{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "dirname = os.path.dirname('__file__')\n",
    "\n",
    "sys.path.append(os.path.join(dirname, \"pkg\"))\n",
    "sys.path.append(os.path.join(dirname, \"pkg\", \"preproc\"))\n",
    "from pkg.preproc import base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objectives\n",
    "\n",
    "1. Identify number of potential speakers (clustering)\n",
    "    1.1 Use Factors: Readability (F-K), doc_length, n_mentions, n_hashtags, time_of_day??, avg_word_size, avg_num_syllables\n",
    "2. Attempt to identify Trump (with 'known' data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17433/17433 [06:56<00:00, 41.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Error: \n",
      "4746) Iran humiliated the United States with the capture of our 10 sailors. Horrible pictures and images. We are weak. I will NOT forget!\n",
      "Length Error: \n",
      "4748) Iran humiliated the United States with the capture of our 10 sailors. Horrible pictures and images. We are weak. I will NOT forget!\n"
     ]
    }
   ],
   "source": [
    "from pkg.mod import cluster\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pandas import DataFrame\n",
    "fields = [\"n_hashtags\", \"n_mentions\", \"avg_syllables\",\n",
    "          \"avg_word_length\", \"fk\", 'n_sents',\n",
    "          \"n_ents\", \"n_uppers\", \"platform_id\",'amplifier',\n",
    "          'analneg', 'attribadj', 'auxdo', 'bemv',\n",
    "          'bracket', 'caps', 'cconj', 'cntrstconj',\n",
    "          'colon', 'comma', 'defart', 'detquan',\n",
    "          'exclam', 'fstpp', 'fulstop', 'gerund',\n",
    "          'havemv', 'imperative', 'indefart',\n",
    "          'infinitive', 'it', 'mdnec',\n",
    "          'mdposs', 'mdpred', 'multiwvb',\n",
    "          'nomin', 'numdet', 'numnoun', 'objpro',\n",
    "          'otheradv', 'othrintj', 'othrnoun',\n",
    "          'othrverb', 'passive', 'past', 'perceptvb',\n",
    "          'perfect', 'posesprpn', 'possdet', 'predadj',\n",
    "          'prep', 'procontract', 'progressive',\n",
    "          'proquan', 'provdo', 'prpn', 'prvv', 'pubv',\n",
    "          'ques', 'relclausesubgap', 'sinflect',\n",
    "          'sndpp', 'stancevb', 'subjpro', 'superlative',\n",
    "          'thrdpp', 'timeadv', 'whw', 'initialmention']\n",
    "dat = base.Data()\n",
    "prep = base.Preprocessor()\n",
    "dat.get_data(load_local=True)\n",
    "\n",
    "prep.tokenize(data=dat.data)\n",
    "\n",
    "ids_ = [d.ID for d in prep.docs]\n",
    "arrs = [d.feature_array for d in prep.docs]\n",
    "df = DataFrame(arrs, index=ids_, columns=fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting OPTICS(metric='l2', min_cluster_size=500, xi=7.5e-05)...\n",
      "Fitted.\n",
      "\n",
      "Pickling...\n",
      "Saved.\n",
      "[-1  0  1  2]\n",
      "{-1: 15132, 2: 1094, 0: 584, 1: 507}\n",
      "17317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magicman/.local/lib/python3.8/site-packages/sklearn/cluster/_optics.py:804: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    }
   ],
   "source": [
    "tod_map = {}\n",
    "dates, times, tokens = [], [], []\n",
    "platforms = []\n",
    "for d in prep.docs:\n",
    "    dates.append(datetime.strptime(d.local_date, \"%Y-%m-%d\"))\n",
    "    tm = d.local_time\n",
    "    times.append(tm)\n",
    "    platforms.append(d.platform)\n",
    "    tokens.append(\",\".join(d.get_tokens_merged(lowercase=False)))\n",
    "df.insert(0, \"tokens\", tokens)\n",
    "df.insert(0, 'date', dates)\n",
    "df.insert(0, 'time', times)\n",
    "df.insert(0, 'platform', platforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android_token           android_count  iphone_token           iphone_count\n",
      "--------------------  ---------------  -------------------  --------------\n",
      "stupid                             52  Join                            145\n",
      "Ebola                              41  Military                         41\n",
      "Friends                            29  Cuts                             37\n",
      "warming                            25  DACA                             36\n",
      "Trump National Doral               24  prayers                          35\n",
      "hell                               23  Video                            33\n",
      "West Africa                        22  Fake News                        27\n",
      "ENJOY                              20  Puerto Rico                      24\n",
      "GLOBAL                             18  the White House                  21\n",
      "WARMING                            18  Repeal                           21\n",
      "shirts                             17  Anthem                           18\n",
      "Celebrity Apprentice               15  Replace                          17\n",
      "Snowden                            15  TAX                              15\n",
      "Atlantic City                      14  via                              15\n",
      "Celebrity                          14  unemployment                     14\n",
      "turbines                           13  Border                           14\n",
      "Baltimore                          12  received                         13\n",
      "Turnberry                          12  HealthCare                       13\n",
      "8:00                               12  Healthcare                       13\n",
      "moron                              12  CUTS                             12\n",
      "wind                               12  Administration                   12\n",
      "cast                               10  Luther Strange                   12\n",
      "wild                               10  premiums                         12\n",
      "VP.                                10  2018                             11\n",
      "SAD                                10  step                             11\n",
      "7.00                               10  Reform                           11\n",
      "bet                                 9  the Fake News                    11\n",
      "Mike                                9  Pence                            11\n",
      "Ben Carson                          9  you-                             11\n",
      "climate                             9  Working                          10\n",
      "mistakes                            8  emails                           10\n",
      "sued                                8  FEMA                             10\n",
      "liked                               8  email                            10\n",
      "NY.                                 8  Cut                               9\n",
      "seriously                           8  meddling                          9\n",
      "Palm Beach                          8  the Fake News Media               9\n",
      "CLIMATE                             8  HEROES                            9\n",
      "ass                                 8  James Comey                       9\n",
      "episodes                            8  Departing                         9\n",
      "either                              7  Order                             9\n"
     ]
    }
   ],
   "source": [
    "from pkg.utils import make_tokens_list\n",
    "from tabulate import tabulate\n",
    "\n",
    "all_tokens = make_tokens_list(df['tokens'])\n",
    "android_tokens_series = df.loc[[i for i in df.index\n",
    "                                if df.loc[i]['platform']=='android']]['tokens']\n",
    "android_tokens = make_tokens_list(android_tokens_series)\n",
    "iphone_tokens_series = df.loc[[i for i in df.index\n",
    "                               if df.loc[i]['platform']=='iphone']]['tokens']\n",
    "iphone_tokens = make_tokens_list(iphone_tokens_series)\n",
    "\n",
    "\n",
    "words_counter = dict(Counter(all_tokens).most_common())\n",
    "android_counter = dict(Counter(android_tokens).most_common())\n",
    "iphone_counter = dict(Counter(iphone_tokens).most_common())\n",
    "\n",
    "\n",
    "android_words_unique = [(k, android_counter[k]) for k in android_counter.keys()\n",
    "                        if k not in iphone_counter]\n",
    "\n",
    "iphone_words_unique = [(kx, iphone_counter[kx]) for kx in iphone_counter.keys()\n",
    "                       if kx not in android_counter]\n",
    "\n",
    "sidexside = [(*android_words_unique[ix], *iphone_words_unique[ix]) for ix in range(40)]\n",
    "combined_table = tabulate(sidexside, headers=(\"android_token\", \"android_count\", 'iphone_token', 'iphone_count'))\n",
    "\n",
    "print(combined_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Difference Between IPhone and Android\n",
    "\n",
    "Its clear just from looking at the most common tokens that\n",
    "the posts originating from Android are more \"incendiary\" in terms\n",
    "of the insulting tone of many keywords. While this is certainly a characteristic\n",
    "one might associate with Trump it is not enough by itself to support the\n",
    "contention that Trump wrote all of these himself.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mod0 = cluster(data=arrs, cluster_meth='optics', xi=.000075,\n",
    "               metric='l2', min_cluster_size=500)\n",
    "\n",
    "mod0_labs = mod0.labels_\n",
    "print(np.unique(mod0_labs))\n",
    "print(dict(Counter(mod0_labs)))\n",
    "\n",
    "print(len(mod0_labs))\n",
    "\n",
    "df.insert(len(df.columns), \"cluster\", mod0_labs)\n",
    "\n",
    "tod_map = {}\n",
    "dates, times, tokens = [], [], []\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining filters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts = df['cluster']\n",
    "\n",
    "outlier_filt = clusts == -1\n",
    "clust_filt = clusts != -1\n",
    "\n",
    "df_outliers = df.where(outlier_filt)\n",
    "df_clusts = df.where(clust_filt)\n",
    "df_outliers = df_outliers.dropna()\n",
    "df_clusts = df_clusts.dropna()\n",
    "grps = df_clusts.groupby(['cluster'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import strptime\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "fieldsx = fields.copy()\n",
    "fieldsx.append('cluster')\n",
    "fig = sns.pairplot(df[fieldsx], hue='cluster')\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('plots/lang_attrs.png')\n",
    "\n",
    "maybe_trump_df = df.loc[[idx for idx in df.index\n",
    "                         if (df.loc[idx]['platform'] == 'android'\n",
    "                             or df.loc[idx]['platform'] == 'web client')\n",
    "                         or df.loc[idx]['date'] <=  datetime(2017, 1, 20)\n",
    "                         or (df.loc[idx]['date'] > datetime(2017, 1, 20) and\n",
    "                             13 > strptime(df.loc[idx]['time'], \"%H:%M:%S\").tm_hour > 10)\n",
    "                         ]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-abb1a51f",
   "language": "python",
   "display_name": "PyCharm (receipts)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}