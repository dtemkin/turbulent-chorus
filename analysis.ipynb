{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"pkg\")\n",
    "sys.path.append(os.path.join(\"pkg\", \"preproc\"))\n",
    "from pkg.preproc import base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objectives\n",
    "\n",
    "1. Identify number of potential speakers (clustering)\n",
    "    1.1 Use Factors: Readability (F-K), doc_length, n_mentions, n_hashtags, time_of_day??, avg_word_size, avg_num_syllables\n",
    "2. Attempt to identify Trump (with 'known' data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4753/17433 [02:53<07:28, 28.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Error: \n",
      "4746) Iran humiliated the United States with the capture of our 10 sailors. Horrible pictures and images. We are weak. I will NOT forget!\n",
      "Length Error: \n",
      "4748) Iran humiliated the United States with the capture of our 10 sailors. Horrible pictures and images. We are weak. I will NOT forget!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17433/17433 [09:56<00:00, 29.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from mod import cluster\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pandas import DataFrame\n",
    "dat = base.Data()\n",
    "prep = base.Preprocessor()\n",
    "dat.get_data(load_local=True)\n",
    "\n",
    "prep.tokenize(data=dat.data)\n",
    "\n",
    "ids_ = [d.ID for d in prep.docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting OPTICS(metric='l1', min_cluster_size=500, xi=0.00025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magicman/.local/lib/python3.6/site-packages/sklearn/cluster/_optics.py:804: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted.\n",
      "\n",
      "Pickling...\n",
      "Saved.\n",
      "[-1  0]\n",
      "{-1: 16766, 0: 551}\n",
      "17317\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tokens_merged'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1b786d3dc481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens_merged'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mall_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens_merged'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tokens_merged'"
     ]
    }
   ],
   "source": [
    "mod0 = cluster(data=prep.arrs, cluster_meth='optics', xi=.00025, \n",
    "               metric='euclidean', min_cluster_size=500)\n",
    "\n",
    "mod0_labs = mod0.labels_\n",
    "print(np.unique(mod0_labs))\n",
    "print(dict(Counter(mod0_labs)))\n",
    "\n",
    "print(len(mod0.labels_))\n",
    "fields = [\"n_hashtags\", \"n_mentions\", \"avg_syllables\", \n",
    "          \"avg_word_length\", \"fk\", 'n_sents', \n",
    "          \"n_ents\", \"n_uppers\", \"platform_id\",'amplifier',\n",
    "          'analneg', 'attribadj', 'auxdo', 'bemv',\n",
    "          'bracket', 'caps', 'cconj', 'cntrstconj',\n",
    "          'colon', 'comma', 'defart', 'detquan',\n",
    "          'exclam', 'fstpp', 'fulstop', 'gerund',\n",
    "          'havemv', 'imperative', 'indefart', \n",
    "          'infinitive', 'it', 'mdnec', \n",
    "          'mdposs', 'mdpred', 'multiwvb',\n",
    "          'nomin', 'numdet', 'numnoun', 'objpro',\n",
    "          'otheradv', 'othrintj', 'othrnoun',\n",
    "          'othrverb', 'passive', 'past', 'perceptvb',\n",
    "          'perfect', 'posesprpn', 'possdet', 'predadj', \n",
    "          'prep', 'procontract', 'progressive', \n",
    "          'proquan', 'provdo', 'prpn', 'prvv', 'pubv', \n",
    "          'ques', 'relclausesubgap', 'sinflect', \n",
    "          'sndpp', 'stancevb', 'subjpro', 'superlative', \n",
    "          'thrdpp', 'timeadv', 'whw', 'initialmention']\n",
    "\n",
    "df = DataFrame(prep.arrs, index=ids_, columns=fields)\n",
    "df_simp = DataFrame(index=ids_)\n",
    "df.insert(len(df.columns), \"cluster\", mod0_labs)\n",
    "tod_map = {}\n",
    "dates, times, tokens = [], [], []\n",
    "all_tokens = []\n",
    "for d in prep.docs:\n",
    "    dates.append(datetime.strptime(d.local_date, \"%Y-%m-%d\"))\n",
    "    tm = time.strptime(d.local_time, \"%H:%M:%S\")\n",
    "    times.append(tm)\n",
    "    tokens.append(d.get_tokens_merged(lowercase=True))\n",
    "    all_tokens.extend(d.get_tokens_merged(lowercase=True))\n",
    "df.insert(0, \"tokens\", tokens)\n",
    "df.insert(0, 'date', dates)\n",
    "df.insert(0, 'time', times)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts = df['cluster']\n",
    "\n",
    "outlier_filt = clusts == -1\n",
    "clust_filt = clusts != -1\n",
    "\n",
    "df_outliers = df.where(outlier_filt)\n",
    "df_clusts = df.where(clust_filt)\n",
    "df_outliers = df_outliers.dropna()\n",
    "df_clusts = df_clusts.dropna()\n",
    "grps = df_clusts.groupby(['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "pyLDAvis.enable_notebook(local=True)\n",
    "model_file = '/tmp/models/lda/base.model'\n",
    "\n",
    "id2word = Dictionary(tokens)\n",
    "#print(list(cmn_dict.items()))\n",
    "\n",
    "def base_model(f, *args, **kwargs):\n",
    "    if os.path.isfile(f):\n",
    "        mod = LdaModel.load(f)\n",
    "    else:\n",
    "        mod = LdaModel(cmn_corpus, *args, **kwargs)\n",
    "        mod.save(model_file)\n",
    "    return mod\n",
    "\n",
    "def convert_id_to_word(_id, id2word_dict):\n",
    "    dct = dict(id2word_dict)\n",
    "    if all([type(dk) == str for dk in dct]):\n",
    "        dct_type=str\n",
    "    else:\n",
    "        dct_type=int\n",
    "    try:\n",
    "        w = dct[dct_type.__call__(_id)]\n",
    "    except KeyError as errmsg:\n",
    "        raise KeyError(f\"invalid id {_id} not found in {dct}\")\n",
    "    else:\n",
    "        return w\n",
    "    \n",
    "for grp in grps:\n",
    "    n_topics = 20\n",
    "    grp_tokens = list(grp[1]['tokens'].values)\n",
    "\n",
    "    grp_corpus = [cmn_dict.doc2bow(text) for text in grp_tokens]\n",
    "    \n",
    "    mod = LdaModel(grp_corpus, id2word=dict(cmn_dict.items()), num_topics=n_topics, alpha='auto')\n",
    "    \n",
    "    for topic_id in range(n_topics):\n",
    "        terms = [(convert_id_to_word(x[0], id2word), x[1]) for x in list(mod.get_topic_terms(topic_id))]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre2016_df = df.loc[idx for idx in df.index \n",
    "                    if df.loc[idx]['date'] <=  datetime(2017, 1, 20)]\n",
    "\n",
    "print(pre2016_df)\n",
    "\n",
    "post2016_df = df.loc[[idx for idx in df.index \n",
    "                      if df.loc[idx]['date'] > datetime(2017, 1, 20)]]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
